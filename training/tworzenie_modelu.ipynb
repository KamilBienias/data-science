{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tworzenie_modelu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtvmUZ5i2ENH7qqgLWV9S6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamilBienias/data-science/blob/main/training/tworzenie_modelu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_u9XlRB9UGd"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# zapis z csv do df\r\n",
        "df = pd.read_csv('file_name.csv')\r\n",
        "\r\n",
        "# podgląd danych\r\n",
        "df.head()\r\n",
        "\r\n",
        "# statystyki danych numerycznych\r\n",
        "df.describe().apply(lambda x: round(x, 2))\r\n",
        "\r\n",
        "# statystyki danych tekstowych. Można też include=\"category\"\r\n",
        "df.describe(include=\"object\")\r\n",
        "\r\n",
        "# samo df.isnull() zwraca w tabeli True tam gdzie jest brak danych\r\n",
        "df.isnull().sum()\r\n",
        "\r\n",
        "# takie kolumny warto zostawić\r\n",
        "selected_vars = [var1, var4, ...]\r\n",
        "\r\n",
        "# z df wycina kolumny spośród selected_vars\r\n",
        "df_selected = df[selected_vars]\r\n",
        "\r\n",
        "# oddziela dane od targetu, gdy target jest ostatnią koumną\r\n",
        "X = df_selected[df_selected.columns[:-1]]\r\n",
        "# pobiera ostatnią kolumnę target jako Series\r\n",
        "y = df_selected[df_selected.columns[-1]]\r\n",
        "\r\n",
        "\r\n",
        "# oddziela dane od targetu, gdy target nie jest ostatnią kolumną\r\n",
        "# Lista nazw wszystkich kolumn\r\n",
        "all_columns_names = list(df.columns)\r\n",
        "print(all_columns_names)\r\n",
        "# Lista nazw kolumn z atrybutami\r\n",
        "data_columns_names = [column_name for column_name in all_columns_names if column_name != \"target_name\"]\r\n",
        "print(data_columns_names)\r\n",
        "# df zawierająca kolumny z atrybutami\r\n",
        "X = df[data_columns_names]\r\n",
        "print(X)\r\n",
        "# wydobywa target jako Series, gdy nie jest on ostatnią kolumną\r\n",
        "y = df[\"target_name\"]\r\n",
        "print(y)\r\n",
        "\r\n",
        "\r\n",
        "# Zamiana wartości tekstowych na numeryczne (bo sklearn tylko liczby przyjmuje do modeli).\r\n",
        "# Parametr drop_first=True usuwa pierwszą kolumnę, którą jest \"no\" i zostawia \"yes\"\r\n",
        "# Można też z sklearn OneHotEncoding\r\n",
        "X = pd.get_dummies(X, drop_first=True)\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "# dzieli dane. Można stratify=tagret\r\n",
        "# domyślnie X_test zajmuje 25% całego X (można zmienić np test_size=0.2)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\r\n",
        "\r\n",
        "# skalowanie cech numerycznych\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "# dopasowuję tylko do danych treningowych, żeby zapobiec wyciekowi danych ze zbioru testowego\r\n",
        "scaler.fit(X_train)\r\n",
        "\r\n",
        "# ale już transformuje dane treningowe i testowe\r\n",
        "X_train = scaler.transform(X_train)\r\n",
        "X_test = scaler.transform(X_test)\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "# obiekt klasyfikatora lub regresora\r\n",
        "# na przykładzie regresji logistycznej, która jest tak naprawdę klasyfikatorem\r\n",
        "log_reg = LogisticRegression()\r\n",
        "\r\n",
        "# nauczenie modelu\r\n",
        "log_reg.fit(X_train, y_train)\r\n",
        "\r\n",
        "# klasyfikatory mają score accuracy a regresory R2 (odmiana MSE)\r\n",
        "log_reg.score(X_test, y_test)\r\n",
        "\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "# przykładowa lista słowników (tu jeden słownik więc nie trzeba []) dla drzewa decyzyjnego\r\n",
        "params = {'max_depth': np.arange(1, 10),\r\n",
        "         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\r\n",
        "\r\n",
        "grid_search = GridSearchCV(classifier, param_grid=params, scoring='accuracy', cv=5)\r\n",
        "grid_search.fit(X_train, y_train)\r\n",
        "\r\n",
        "# najlepszy estymator, który bierzemy jako model\r\n",
        "grid_search.best_estimator_\r\n",
        "\r\n",
        "# najepsze parametry estymatora\r\n",
        "grid_search.best_params_\r\n",
        "\r\n",
        "# wykres granic decyzyjnych\r\n",
        "from mlxtend.plotting import plot_decision_regions\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 8))\r\n",
        "plot_decision_regions(X_test, y_test, grid_search)\r\n",
        "plt.title(f'Zbiór treningowy: dokładność {grid_search.score(X_train, y_train):.4f}')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# metryka dokładkość (dla klasyfikatorów)\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "accuracy_score(y_test, y_pred)\r\n",
        "\r\n",
        "# dokładność na zbiorze testowym\r\n",
        "grid_search.score(X_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "# macierz pomyłek jako macierz numpy\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "y_pred = classifier.predict(X_test)\r\n",
        "cm = confusion_matrix(y_test, y_pred)\r\n",
        "cm\r\n",
        "\r\n",
        "\r\n",
        "# macierz pomyłek jako heatmapa (mapa ciepła) w seaborn\r\n",
        "plt.figure(figsize=(8, 6))\r\n",
        "plt.title('Macierz konfuzji')\r\n",
        "_ = sns.heatmap(cm, annot=True, cmap=sns.cm.rocket_r)\r\n",
        "\r\n",
        "\r\n",
        "# macierz pomyłek jako heatmapa (mapa ciepła) w plotly (interaktywna)\r\n",
        "import plotly.figure_factory as ff\r\n",
        "\r\n",
        "# w miejsce n wpisać ilość klas \r\n",
        "amount_of_classes = n\r\n",
        "\r\n",
        "columns = ['pred_' + str(i) for i in range(amount_of_classes)]\r\n",
        "index = ['true_' + str(i) for i in range(amount_of_classes)]\r\n",
        "\r\n",
        "def plot_confusion_matrix(cm):\r\n",
        "    # Mulitclass classification, n classes\r\n",
        "    cm = cm[::-1]\r\n",
        "    cm = pd.DataFrame(cm, columns=columns, index=index[::-1])\r\n",
        "\r\n",
        "    fig = ff.create_annotated_heatmap(z=cm.values, x=list(cm.columns), y=list(cm.index), \r\n",
        "                                      colorscale='ice', showscale=True, reversescale=True)\r\n",
        "    fig.update_layout(width=700, height=500, title='Confusion Matrix', font_size=16)\r\n",
        "    fig.show()\r\n",
        "\r\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}