{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tworzenie_modelu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNM5wl8tFT1cXD34TzOPuNe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamilBienias/data-science/blob/main/training/tworzenie_modelu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_u9XlRB9UGd"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# zapis z csv do df\n",
        "df = pd.read_csv('file_name.csv')\n",
        "\n",
        "# podgląd danych\n",
        "df.head()\n",
        "\n",
        "# statystyki danych numerycznych\n",
        "df.describe().apply(lambda x: round(x, 2))\n",
        "\n",
        "# statystyki danych tekstowych. Można też include=\"category\"\n",
        "df.describe(include=\"object\")\n",
        "\n",
        "# samo df.isnull() zwraca w tabeli True tam gdzie jest brak danych\n",
        "df.isnull().sum()\n",
        "\n",
        "# takie kolumny warto zostawić\n",
        "selected_vars = [var1, var4, ...]\n",
        "\n",
        "# z df wycina kolumny spośród selected_vars\n",
        "df_selected = df[selected_vars]\n",
        "\n",
        "# oddziela dane od targetu, gdy target jest ostatnią koumną\n",
        "X = df_selected[df_selected.columns[:-1]]\n",
        "# pobiera ostatnią kolumnę target jako Series\n",
        "y = df_selected[df_selected.columns[-1]]\n",
        "\n",
        "\n",
        "# oddziela dane od targetu, gdy target nie jest ostatnią kolumną\n",
        "# Lista nazw wszystkich kolumn\n",
        "all_columns_names = list(df.columns)\n",
        "print(all_columns_names)\n",
        "# Lista nazw kolumn z atrybutami\n",
        "data_columns_names = [column_name for column_name in all_columns_names if column_name != \"target_name\"]\n",
        "print(data_columns_names)\n",
        "# df zawierająca kolumny z atrybutami\n",
        "X = df[data_columns_names]\n",
        "print(X)\n",
        "# wydobywa target jako Series, gdy nie jest on ostatnią kolumną\n",
        "y = df[\"target_name\"]\n",
        "print(y)\n",
        "\n",
        "\n",
        "# Zamiana wartości tekstowych na numeryczne (bo sklearn tylko liczby przyjmuje do modeli).\n",
        "# Parametr drop_first=True usuwa pierwszą kolumnę, którą jest \"no\" i zostawia \"yes\"\n",
        "# Można też z sklearn OneHotEncoding\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# dzieli dane. Można stratify=tagret\n",
        "# domyślnie X_test zajmuje 25% całego X (można zmienić np test_size=0.2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# skalowanie cech numerycznych\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "# dopasowuję tylko do danych treningowych, żeby zapobiec wyciekowi danych ze zbioru testowego\n",
        "scaler.fit(X_train)\n",
        "# ale już transformuje dane treningowe i testowe\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# średnie wszystkich cech numerycznych\n",
        "scaler.mean_\n",
        "# odchylenia standardowe cech numerycznych\n",
        "scaler.scale_\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# obiekt klasyfikatora lub regresora\n",
        "# na przykładzie regresji logistycznej, która jest tak naprawdę klasyfikatorem\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# nauczenie modelu\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# klasyfikatory mają score accuracy a regresory R2 (odmiana MSE)\n",
        "log_reg.score(X_test, y_test)\n",
        "\n",
        "# predykcja klasy 0 lub 1\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# predykcja prawdopodobieństw (probability) przynależności do klas odpowiednio 0 i 1.\n",
        "# Na przykład [0.12, 0.88] oznacza, że z p-twem 0.88 przewidzi klasę 1\n",
        "y_prob = log_reg.predict_proba(X_test)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# przykładowa lista słowników (tu jeden słownik więc nie trzeba []) dla drzewa decyzyjnego\n",
        "params = {'max_depth': np.arange(1, 10),\n",
        "         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
        "\n",
        "grid_search = GridSearchCV(classifier, param_grid=params, scoring='accuracy', cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# najlepszy estymator, który bierzemy jako model\n",
        "grid_search.best_estimator_\n",
        "\n",
        "# najepsze parametry estymatora\n",
        "grid_search.best_params_\n",
        "\n",
        "# wykres granic decyzyjnych\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_decision_regions(X_test, y_test, grid_search)\n",
        "plt.title(f'Zbiór treningowy: dokładność {grid_search.score(X_train, y_train):.4f}')\n",
        "plt.show()\n",
        "\n",
        "# metryka dokładkość (dla klasyfikatorów)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_test, y_pred)\n",
        "\n",
        "# dokładność na zbiorze testowym\n",
        "grid_search.score(X_test, y_test)\n",
        "\n",
        "\n",
        "# macierz pomyłek - przypadek 2x2\n",
        "\n",
        "#         pred_0   pred_1\n",
        "# true_0\n",
        "# true_1\n",
        "\n",
        "# Błąd alfa (I rodzaju), gdy naprawdę był zdrowy, a przewidziany jako chory (mało groźny błąd).\n",
        "# Błąd beta (II rodzaju), gdy naprawdę był chory, a przewidziany jako zdrowy (groźny błąd).\n",
        "\n",
        "# macierz pomyłek jako macierz numpy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm\n",
        "\n",
        "# wbudowana funkcja ryzująca macierz pomyłek\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "plot_confusion_matrix(cm)\n",
        "\n",
        "# macierz pomyłek jako heatmapa (mapa ciepła) w seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title('Macierz konfuzji')\n",
        "_ = sns.heatmap(cm, annot=True, cmap=sns.cm.rocket_r)\n",
        "\n",
        "\n",
        "# macierz pomyłek jako heatmapa (mapa ciepła) w plotly (interaktywna)\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "# w miejsce n wpisać ilość klas \n",
        "amount_of_classes = n\n",
        "\n",
        "columns = ['pred_' + str(i) for i in range(amount_of_classes)]\n",
        "index = ['true_' + str(i) for i in range(amount_of_classes)]\n",
        "\n",
        "def plot_confusion_matrix(cm):\n",
        "    # Mulitclass classification, n classes\n",
        "    cm = cm[::-1]\n",
        "    cm = pd.DataFrame(cm, columns=columns, index=index[::-1])\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(z=cm.values, x=list(cm.columns), y=list(cm.index), \n",
        "                                      colorscale='ice', showscale=True, reversescale=True)\n",
        "    fig.update_layout(width=700, height=500, title='Confusion Matrix', font_size=16)\n",
        "    fig.show()\n",
        "\n",
        "plot_confusion_matrix(cm)\n",
        "\n",
        "# raport klasyfikacji\n",
        "from sklearn.metrics import classification_report\n",
        "# target_names to nazwy wartości jakie przyjmuje target\n",
        "# na przykład dla iris będzie to lista ['setosa' 'versicolor' 'virginica']\n",
        "# Nie mylić z wartościami targetu którymi są: 0,1,2\n",
        "print(classification_report(y_test, y_pred, target_names=['setosa' 'versicolor' 'virginica']))\n",
        "\n",
        "\n",
        "# zapis i odczyt modelu (pierwszy sposób)\n",
        "import pickle\n",
        "# zapisu model do pliku\n",
        "# wb to write binary\n",
        "with open('/home/dell/PycharmProjects/dash-tut/08_case_studies_2/model.pickle', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "# odczyt modelu\n",
        "# tryb rb czyli read binary\n",
        "with open('/home/dell/PycharmProjects/dash-tut/08_case_studies_2/model.pickle', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "\n",
        "# zapis i odczyt modelu (drugi sposób)\n",
        "# utrwalanie modelu (model persisting)\n",
        "from sklearn.externals import joblib\n",
        "# zapis modelu do pliku\n",
        "joblib.dump(model, \"model_name.joblib\")\n",
        "# odczytanie modelu z pliku\n",
        "model = joblib.load(\"model_name.joblib\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}